\documentclass[10pt]{article}
\usepackage{graphicx,amsmath,amsthm, amssymb,setspace}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, total={6in, 8.5in}]{geometry}
\usepackage{cite}

\theoremstyle{definition}
\newtheorem{defin}{Definition}
\newtheorem{assumption}{Assumption} 
\theoremstyle{plain}
\newtheorem{lemma}{Lemma}%[section]
\newtheorem{example}{Example}
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}

\def\DM{\protect{$\cal{DM}$}}
\def\interior{\protect{\textnormal{int}}}
\def\closure{\protect{\textnormal{closure}}}
\def\rank{\protect{\textnormal{rank}}}
\def\diagonal{\protect{\textnormal{diag}}}

\title{An interior point method for conic programming with exponential cone constraints}

\begin{document}
\maketitle

\begin{abstract}
We introduce the concept of exponential cone, expression of its dual cone, barrier functions, and a homogeneous interior-point method for conic programming with exponential cone constraints.
\end{abstract}

\section{Definitions and preliminaries}
The following notations, definitions and basic properties are adopted from \cite{Robert_thesis} and \cite{Akle_thesis}.

\begin{defin} Denote $\mathbb{R}_+ = \left\{x \mid x\in \mathbb{R}, x\geq 0\right\}$ and $\mathbb{R}_{++} = \left\{x \mid x\in \mathbb{R}, x> 0\right\}$. For a vector $x = (x_1, \cdots, x_n)^T \in \mathbb{R}^n$, denote the diagonal matrix with entries $x_1, \cdots, x_n$ as $\diagonal(x)$. A subset $\mathcal{K}$ of an Euclidean space $\mathbb{R}^n$ is a \textit{(pointed) convex cone} if (1) $\mathbf{0} \in \mathcal{K}$, (2) for any $\alpha, \beta \in \mathbb{R}_+$ and $x,y \in \mathcal{K}$, one has $\alpha x + \beta y \in \mathcal{K}$, and (3) the only linear subspace of $\mathbb{R}^n$ contained in $\mathcal{K}$ is $\left\{0\right\}$. A \textit{proper cone} is a convex cone that is pointed, closed and has non-empty interior in the usual Euclidean space topology.
\end{defin}

\begin{defin}
	For a convex cone $\mathcal{K} \in \mathbb{R}^n$, its \textit{dual cone} is defined as 
	\[\mathcal{K}^* = \left\{y\in \mathbb{R}^n \mid x^T y\geq 0, \forall x \in \mathcal{K} \right\}.\]
	A proper cone $\mathcal{K}$ is called \textit{self-dual} if $\mathcal{K}^* = \mathcal{K}$.
\end{defin}
\begin{prop}
	For a proper cone $\mathcal{K} \in \mathbb{R}^n$, its dual cone $\mathcal{K}^*$ is also a proper cone and  $(\mathcal{K}^*)^* = \mathcal{K}$. 
\end{prop}


\begin{defin}
	The \textnormal{Lorentz cone} of dimension $n\geq 2$ is defined as
	\[\mathcal{Q}_n = \left\{ x \in \mathbb{R}^n \mid x_1 \geq \sqrt{x_2+\cdots+x_n} \right\}. \]
\end{defin}
Note that there are slightly different definitions of the Lorentz cone, namely, some authors prefer interchanging the role of $x_1$ and $x_n$. \\
\begin{prop}
	Both the positive orthant and the Lorentz cone are self-dual. In other words, $(\mathbb{R}_+^n)^* = \mathbb{R}_+^n$ and $(\mathcal{Q}_m)^* = \mathcal{Q}_m$ for $n\geq 1$, $m\geq 2$.
\end{prop}
The positive orthant, the Lorenz cone and the positive semidefinite cone $\mathcal{S}^n_+ = \left\{ X \in \mathcal{S}^{n} \mid X\succeq 0 \right\}$, (where $\mathcal{S}^n$ denotes the symmetric matrices in $\mathbb{R}^{n\times n}$) are known as \textit{symmetric cones} (there are other less interesting types of symmetric cones).
\begin{defin}
	Let 
	\[\mathcal{K}^0_{\exp} = \left\{(x, y, z) \in \mathbb{R}^3 \mid y \geq 0, z > 0, \exp\left(\dfrac{x}{z}\right) \leq \dfrac{y}{z}\right\}\] 
	and define the \textit{exponential cone} as the closure of $\mathcal{K}^0_{\exp}$ in $\mathbb{R}^3$, 
	\[\mathcal{K}_{\exp} = \textnormal{closure}\left(K^0_{\exp}\right).\]
\end{defin}
\begin{prop}\label{K_exp=K0_exp_union_something}
	One has $\mathcal{K}_{\exp} = K^0_{\exp} \cup \left[\left(-\mathbb{R}_+\right) \times \mathbb{R}_+ \times \{0\} \right]$.
\end{prop}

\begin{defin}
	Let $\mathcal{P}^0_{\exp} = \left\{(u,v,w) \in \mathbb{R}^3 \mid u<0, v \geq 0, \exp\left(\dfrac{w}{u}\right)\leq -\dfrac{e\cdot v}{u} \right\}$
	and define $\mathcal{P}_{\exp} = \textnormal{closure} \left(\mathcal{P}^0_{\exp}\right)$,
	where $e$ denotes the base of natural logarithm. 
\end{defin}
\begin{prop}
	One has $\mathcal{P}_{\exp} = \mathcal{P}^0_{\exp} \cup \{0\} \times \mathbb{R}_+ \times \mathbb{R}_+$ and $ (\mathcal{K}_{\exp})^* = \mathcal{P}_{\exp}$.
\end{prop}

We will be primarily working with the above three types of proper cones, namely, the positive orthants $\mathbb{R}_+^{n}$, the Lorentz cone $\mathcal{Q}^m$ and the exponential cone $\mathcal{K}_{\exp}$. In other words, the interior-point method we present deals with problems with a conic constraint $s \in \mathcal{K}$, where $\mathcal{K}$ is a Cartesian product of these three types of cones.\\

In theory, all polynomial-time interior-point methods for conic programming problems require a well-defined and computable (up to the Hessian) barrier function for the cone.

\begin{defin}
	Let $\mathcal{K} \subset \mathbb{R}^n$ be a closed convex set with $\textnormal{int}\left(\mathcal{K}\right) \neq \emptyset$, and $f: \textnormal{int} \left(\mathcal{K}\right) \rightarrow \mathbb{R}$ be strictly convex. The function $f$ is called a \textit{self-concordant barrier} for $\mathcal{K}$  if 
	\begin{enumerate}
		\item (barrier property) for any sequence of points $\{x_n\}$ such that $\lim x_n \in \mathcal{K}\backslash \textnormal{int}\left(\mathcal{K}\right)$, one has $\lim f(x_n) = \infty$,
		\item (differentiability) $f$ has continuous third-order mixed partial derivatives, and
		\item (self-concordance) for any $x \in \textnormal{int}\left(\mathcal{K}\right)$ and $v \in \mathbb{R}^n$, the function $\phi(t) = f(x+tv)$ satisfies $|\phi ''' (t)|\leq M_f \left(\phi '' (t)\right)^{2/3}$ for some constant $M_f \geq 0$ and all $t$ such that $tv \in \textnormal{int}\left(\mathcal{K}\right)$.
	\end{enumerate}
\end{defin}

\begin{defin}
	Let $\mathcal{K}$ be a proper cone. The function $f: \textnormal{int}\left(\mathcal{K}\right)\rightarrow \mathbb{R}$ is called a logarithmically homogeneous self-concordant barrier (LHSCB) for $\mathcal{K}$ with parameter $\nu$ if $f$ is a self-concordant barrier for $\mathcal{K}$ and for all $x \in \textnormal{int}\left(\mathcal{K}\right)$ and $t>0$, one has 
	\[f(tx) = f(x) - \nu \log t.\]
\end{defin}

Below is an important property of logarithmically homogeneous self-concordant barriers (see Theorem 4.3.4 in \cite{Akle_thesis}).
\begin{prop} \label{conjugate_of_LHSCB_is_LHSCB_for_dual}
	Let $\mathcal{K}$ be a proper cone and $f$ a LHSCB for $\mathcal{K}$ with parameter $\nu$. The \textnormal{conjugate barrier} of $f$, denoted as $f^*$, defined on $\textnormal{int}(\mathcal{K}^*)$ by 
	\[f^*(s) = \sup \left\{-s^Tx -f(x) \mid x\in \textnormal{int}\left(\mathcal{K}\right)  \right\}\]
	is a LHSCB for $\mathcal{K}^*$ with parameter $\nu$. Furthermore, one has $(f^*)^* = f$.
\end{prop}
Note that the definition of conjugate barrier in this context is slightly different from the definition of convex conjugate adopted in standard references of convex analysis. \\

We list some useful barriers for the important types of cones.

\begin{prop} \label{barriers_for_linear_and_lorentz_cone}
	\textnormal{(Section 2 of \cite{CVX})} The function 
	\[f_l(x) =-\sum_{i=1}^n \log x_i\]
	is a LHCSB for the nonnegative orthant $\mathbb{R}_+^{n}$ with $\nu = n$. Its gradient and Hessian are
	\[\nabla g_l(x) = f_l(x)= \begin{bmatrix}
	-\dfrac{1}{x_1} \\[2ex] \vdots \\[2ex] -\dfrac{1}{x_n} \\[1ex]
	\end{bmatrix},\quad 
	H_l(x) = \nabla^2 f_l(x) = \begin{bmatrix}
	\dfrac{1}{x_1^2} & 			  &				 			 \\[2ex] 
							& \ddots &						    \\[2ex] 
							&			 &	\dfrac{1}{x_n^2} \\[1ex]
	\end{bmatrix}. \]
	The function 
	\[f_q(x) = -\dfrac{1}{2}\log\left(x_1^2 - ||\tilde{x}||^2\right)\]
	where $\tilde{x} = \left(x_2,\cdots,x_n\right)^T$ and $||\cdot|| = ||\cdot||_2$ is a LHSCB for $\mathcal{Q}_n$ with $\nu = 2$. The gradient and Hessian of $f_q$ are
	\[g_q(x) = - \dfrac{1}{x^T J x} Jx, \quad H_q(x) =  \dfrac{1}{(x^T J x)^2}\left(2Jxx^T J - (x^T J x)J\right) \]
	where $J = \begin{bmatrix}
	1 & \\ & -I_{n-1}
	\end{bmatrix}$.
\end{prop}

In \cite{Akle_thesis}, the author listed two different pairs of conjugate barriers (LHSCB) for the exponential cone and its dual cone.

\begin{defin}
	The Wright Omega function $\omega: \mathbb{R} \rightarrow \mathbb{R}_{++}$ is defined as the unique solution to the equation 
	\[\omega(\beta) + \log \omega(\beta) = \beta \]
	for $\beta \in \mathbb{R}$.
\end{defin}

\begin{prop}
	The function $f_{\exp}: \textnormal{int}\left(\mathcal{K}_{\exp}\right) \rightarrow \mathbb{R}$ defined by 
	\[f_{\exp}(x,y,z) = -\log\left(z\log \left(\dfrac{y}{z}\right)-x\right) - \log y - \log z\]
	is a LHSCB for $\mathcal{K}_{\exp}$  with $\nu = 3$. 	Its conjugate $f_{\exp}^*: \textnormal{int}\left(\mathcal{P}_{\exp}\right) \rightarrow \mathbb{R}$, which is a LHSCB for $\left(\mathcal{K}_{\exp}\right)^* = \mathcal{P}_{\exp}$ with $\nu = 3$, takes the following expression 
	\[f_{\exp}^*(u,v,w) = -2 \log(-u) -\log v -\log\left(\dfrac{(1-\bar{\omega})^2}{\bar{\omega}}\right) - 3 \]
	where 
	\[\bar{\omega} = \omega\left(2-\dfrac{w}{u} - \log (-u) + \log v \right). \]
\end{prop}

Note that the dual barrier $f_{\exp}^*$ above has a slightly more complicated expression than the primal barrier $f_{\exp}$. It is not too difficult to work out another pair of conjugate barrier functions where the dual barrier takes a slightly simpler expression instead. In fact, there exists an invertible linear transformation $B: \mathbb{R}^3 \rightarrow \mathbb{R}^3 $ such that $B\left(\textnormal{int} \left(\mathcal{K}_{\exp}\right)\right) = \textnormal{int} \left(\mathcal{P}_{\exp}\right)$, which is given by the matrix 
\[ B =  \begin{bmatrix}
     &    & -1 \\[1ex]
     &  \dfrac{1}{e} &     \\[1ex]
 -1 &    & 
\end{bmatrix}. \]
As such, $\tilde{f}_{\exp}(x,y,z) = f^*_{\exp}(B (x,y,z))$ is a LHSCB for $\mathcal{K}_{\exp}$ and $\tilde{f}_{\exp}^*(u,v,w) = f_{\exp}(B^{-1}(u,v,w))$ is its conjugate barrier, which is a LHSCB for $\mathcal{P}_{\exp}$. Note that by the definition of conjugate barrier and the property of LHSCB, we may also take $\tilde{f}_{\exp} + \beta$ and $ \left(\tilde{f}_{\exp} + \beta\right)^* = \tilde{f}^*_{\exp} - \beta $ as the LHSCBs for $\mathcal{K}_{\exp}$ and $\mathcal{P}_{\exp}$, respectively, for any $\beta \in \mathbb{R}$.

\begin{prop}
	The function $\tilde{f}_{\exp}: \textnormal{int}\left(\mathcal{K}_{\exp}\right)\rightarrow \mathbb{R}$ defined by
	\[\tilde{f}_{\exp}(x,y,z) = -2 \log z - \log y  - \log \left(\dfrac{(1-\bar{\omega})^2}{\bar{\omega}}\right) - 3 \]
	where 
	\[\bar{\omega} = \omega\left(1-\dfrac{x}{z} - \log z - \log y\right) \]
	is a LHSCB for $\mathcal{K}_{\exp}$ with $\nu = 3$. Its conjugate $\tilde{f}_{\exp}^*: \textnormal{int}\left(\mathcal{P}_{\exp}\right) \rightarrow \mathbb{R}$, which is a LHSCB for $\left(\mathcal{K}_{\exp}\right)^* = \mathcal{P}_{\exp}$ with $\nu=3$, takes the following expression 
	\[\tilde{f}_{\exp}^*(u,v,w) = -\log\left(-t\right) - \log (-u) - \log v\]
	where $r = \log \left(-v/u\right)$ and $t=u-w+ur$.  Furthermore, the gradient and Hessian of the dual barrier at $(u,v,w)^T \in \interior\left(\mathcal{P}_{\exp}\right)$ are \\
	\begin{align*}
	\tilde{g}^*\left((u,v,w)^T\right) &= \nabla \tilde{f}^*_{\exp}(u,v,w) =  
	\begin{bmatrix}
	-\dfrac{r}{t} - \dfrac{1}{u} \\[2ex]
	-\dfrac{1}{v} - \dfrac{u}{vt} \\[2ex]
	\dfrac{1}{t} \\[1ex]
	\end{bmatrix}, \\ \\
	\tilde{H}^*\left((u,v,w)^T\right) &= \nabla^2 \tilde{f}^*_{\exp}(u,v,w) =  
	\begin{bmatrix}
	\dfrac{1}{ut} + \dfrac{r^2}{t^2}+ \dfrac{1}{u^2} & \dfrac{ur}{vt^2} - \dfrac{1}{vt} & -\dfrac{r}{t^2} \\[2ex]
	\dfrac{ur}{vt^2} - \dfrac{1}{vt}  & \dfrac{1}{v^2}+\dfrac{u}{v^2t} + \dfrac{u^2}{v^2t^2} & -\dfrac{u}{vt^2} \\[2ex]
	-\dfrac{r}{t^2}	& -\dfrac{u}{vt^2} & \dfrac{1}{t^2} \\[1.5ex]
	\end{bmatrix}.
	\end{align*}
\end{prop}
Note that once we obtain the expressions of the LHSCB, their gradients and Hessians for the positive orthant, the Lorentz cone and the exponential cone, we can easily construct LHSCB, their gradients and Hessians for any Cartesian product of these cones through vertical and block-diagonal concatenation.

\section{Standard forms of conic programming}
For different purposes, there have been different standard forms in conic programming. The simplest formulation is the following pair of primal and dual problems denoted as (PD), 
\begin{align}
\begin{split} 
\text{Primal:} \quad &\min\,\, c^Tx\\ 
&\textnormal{s.t.} \,\, Ax=b,\ x\in \mathcal{K} \\
\text{Dual:}  \quad &\max\,\, b^Ty \\
&\textnormal{s.t.} \,\, A^Ty+z=c,\ s\in\mathcal{K}^*,\ y \in \mathbb{R}^m \\
\end{split} &\text{(PD)} \nonumber
\end{align}
where $c,x \in \mathbb{R}^n$, $A\in \mathbb{R}^{m\times n}$, $b\in \mathbb{R}^m$ and $\mathcal{K} \subset \mathbb{R}^n$ is a proper cone. Without loss of generality, we further assume $m\leq n$ and $\text{rank}(A) = m$. By the generalized Slater's condition (see \cite{Boyd_Vander_Convex_Opt_Book}), if there exist
$x \in \text{int} \left(\mathcal{K}\right)$ such that $Ax=b$ and $z \in \interior \left(\mathcal{K}^*\right)$ such that $A^Ty+z=c$,
then strong duality holds for (PD). In this case, any primal-dual optimal solution $(x,y,s)$ must satisfy the following KKT system
\begin{align}\label{KKT_for_PD}
\begin{split}
Ax-b=0& \\
A^Ty+z-c=0& \\
x^Tz=0& \\
x\in\mathcal{K}_{\exp},\ z\in\mathcal{P}_{\exp},\ y\in\mathbb{R}^m& 
\end{split}
\end{align}

We introduce the (full) \textit{homogeneous self-dual embedding} of (PD), which is similar to (25) in \cite{SDPT3_2010} and (27) in \cite{CVX},
\begin{align*}
\begin{split}
& \min \,\, \bar{\alpha}\theta \\
& \text{s.t.} \begin{bmatrix}
0 & -A & b & -\bar b\ \\ 
A^T & 0 & -c & \bar c \\
-b^T & c^T& 0 & -\bar g \\
\bar b^T & -\bar c^T & \bar g & 0
\end{bmatrix}
\begin{bmatrix}
y \\ x \\ \tau \\ \theta
\end{bmatrix} + 
\begin{bmatrix}
0 \\ z \\ \kappa \\ 0 
\end{bmatrix} = 
\begin{bmatrix}
0 \\ 0 \\ 0 \\ \bar \alpha
\end{bmatrix}\\
& x \in \mathcal{K},\ z \in \mathcal{K}^*,\ \tau \geq 0,\ \kappa\geq 0,\ y \in \mathbb{R}^m,\ \theta \in \mathbb{R}, 
\end{split} \quad \quad \quad \text{(HSD)}
\end{align*}
where the auxillary parameters $\bar b, \bar c, \bar g$ and $\bar \alpha$ are determined by a given $(x^0, y^0, z^0, \tau^0, \kappa^0, \theta^0)$ such that $x^0 \in \interior \left(\mathcal{K}\right)$, $z^0 \in \interior \left(\mathcal{K}^*\right)$ and $\tau^0, \kappa^0, \theta^0 > 0$, namely,
\begin{align*}
\bar b = \dfrac{1}{\theta^0}\left(b\tau^0 - Ax^0\right),\quad\quad  \bar c = \dfrac{1}{\theta^0}\left(c\tau^0 - A^Ty^0 - z^0\right), \\ 
\bar g = \dfrac{1}{\theta^0}\left(c^T x^0 - b^T y + \kappa\right), \quad\quad  \bar \alpha = \dfrac{1}{\theta^0}\left((x^0)^T z^0 + \tau^0\kappa^0\right).
\end{align*}

The properties of (HSD) are summarized in the following proposition.
\begin{prop}\label{properties_HSD} \textnormal{(Lemma 1 in \cite{Freund_behavior_HSD})}
	For any given $(x^0, y^0, z^0, \tau^0, \kappa^0, \theta^0)$ such that $x^0 \in \interior \left(\mathcal{K}_{\exp}\right)$, $z^0 \in \interior \left(\mathcal{P}_{\exp}\right)$ and $\tau^0, \kappa^0, \theta^0 > 0$, the auxiliary parameters $\bar{b}$, $\bar{c}$, $\bar{g}$, $\bar{\alpha}$ and hence the problem (HSD) are well-defined. One has $\bar{\alpha}>0$. Further more, the following facts hold.
	\begin{enumerate}
		\item The problem (HSD) is \textnormal{self-dual}. In other words, the dual of the problem is equivalent to itself. 
		\item $(x,y,z,\tau,\kappa, \theta) = (x^0,y^0,z^0, \tau^0,\kappa^0, \theta^0)$ is a strictly feasible (primal and dual) solution.
		\item The (attained) optimal objective is 0. 
		\item Assume the solution $(x,y, \tau, z,\kappa, \theta)$ is feasible. One has $\theta\geq 0$ and $x^T z + \tau \kappa = \bar{\alpha} \theta$. Furthermore, the solution is optimal if and only if $\theta=0$, in which case one has $x^T z = \tau\kappa = 0$.
		\item Assume $(x,y, \tau, z,\kappa, 0)$ is an optimal solution. If $\tau>0$ then $(x,y,z)/\tau$ is an optimal solution to (PD). If $\kappa>0$ then either $b^Ty>0$ or $c^Tx<0$ or 	
		both hold. 
		\subitem If $b^T y>0$ then (PD) is primal-infeasible.
		\subitem If $c^T x < 0$ then (PD) is dual infeasible.
		\item \textnormal{(Proposition 3 in \cite{Freund_behavior_HSD})} For any $\epsilon \geq 0$, there exists a feasible solution of (HSD) with objective value equal to $\epsilon$.
	\end{enumerate}
\end{prop} 
Note that if $(y,x,\tau,z,\kappa,0)$ is an optimal solution to (HSD) with $\tau=\kappa=0$, no conclusion can be made regarding  (PD). \\

For implementation purpose, we will adopt the standard form in \cite{SDPT3_2010} which can be written in the form of (PD). Specifically, we consider the following pair of primal and dual problem
\begin{align*}
\begin{split}
\text{Primal:}\quad &\min\,\, \sum_{i=1}^N c_i^Tx_i\\
& \text{s.t.}\,\, \sum_{i=1}^N A_i x_i = b \\
&\quad\quad x_i \in K_i,\ \forall i \\[1ex] 
\text{Dual:} \quad &\max\,\, b^T y\\
& \text{s.t.}\,\, A_i^T y + z_i = c_i, \ \forall i \\
&\quad\quad y \in \mathbb{R}^m,\ z_i \in K_i^*, \forall i \\[1ex]
\end{split} \quad\quad\quad\quad\quad\quad\quad \text{(PD$'$)}
\end{align*}
where $x_i, c_i \in \mathbb{R}^{n_i}$, $A_i \in \mathbb{R}^{m\times n_i}$, $b \in \mathbb{R}^m$ and $n = \sum_{i=1}^N n_i \geq m$. Each $K_i$ is one of the following: (i) the nonnegative orthant $\mathbb{R}_+^{n_i}$, (ii) product of Lorentz cones $\mathcal{Q}^{q_1}\times \cdots \times \mathcal{Q}^{q_{k_i}}$, $\sum_{j=1}^{k_i} q_j = n_i$, (iii) product of the exponential cone  $\left(\mathcal{K}_{\exp}\right)^{k_i}$, $3k_i = n_i$ or (iv) $\mathbb{R}^n_i$. Note that we define (which is consistent with the definition of dual cone) $\left(\mathbb{R}^k\right)^* = \left\{ y \in \mathbb{R}^k \mid y^T x \geq 0,\ \forall x \in \mathbb{R}^k  \right\} = \left\{0\right\}^k$. To write (PD$'$) into (PD), one simply let
\[  A = \begin{bmatrix} A_1,\ \hdots,\  A_N \end{bmatrix},\ \
x = \begin{bmatrix} x_1 \\ \vdots\\ x_N \end{bmatrix},\ \ 
c = \begin{bmatrix} c_1 \\ \vdots \\c_N \end{bmatrix},\ \
z = \begin{bmatrix} z_1 \\ \vdots \\ z_N \end{bmatrix},\ \ \mathcal{K} = K_1 \times \cdots \times K_N,\ \ \mathcal{K}^* = K_1^* \times \cdots \times K_N^*.\]

For notational convenience, vertical concatenation of matrices (or vectors) of appropriate dimensions $(M_1^T,\ M_2^T,\ \cdots,\ M_L^T)^T$ will occasionally be denoted $[M_1; \cdots ; M_L]$.

\section{A homogeneous interior-point algorithm}
Next we describe the algorithm for solving (HSD) (and hence find either a solution to (PD) or certificates of infeasibility) in detail. Henceforth the gradients of the barriers for $\mathcal{K}$ and $\mathcal{K}^*$ will be denoted as $g$ and $g^*$ (in particular, $\mathcal{K}_{\exp}$ and $\mathcal{P}_{\exp}$) respectively, and the Hessians $H$ and $H^*$ respectively.
\subsection{Initialization}

Suppose one has a problem in the form (PD$'$). First, for all $i$ with $K_i = \mathbb{R}^{n_i}$, define $x_i^{new} = [x_i^+; x_i^-]$, $c_i^{new} = [c_i; -c_i]$, $A_i^{new} = [A_i, -A_i]$, $K_i^{new} = \mathbb{R}_+^{n_i^{new}}$, $n_i^{new} = 2n_i$ and replace $c_i^{new}$, $A_i$, $K_i$, $n_i$ by $c_i^{new}$, $A_i^{new}$, $K_i^{new}$ and $n_i^{new}$ respectively. After the above adjustment and necessary rearrangement (grouping together the same types of $K_i$), one has $\mathcal{K} = \mathbb{R}_+^{n_l} \times \mathcal{Q}_{n_{q_1}} \times \cdots \times \mathcal{Q}_{n_{q_s}} \times \left(\mathcal{K}_{\exp}\right)^{k_e}$, $n_q = n_{q_1} + ... + n_{q_s}$, $n_e = 3k_e$. \\

Next we set the iterate $(x^0,y^0, z^0, \tau^0, \kappa^0, \theta^0)$ such that $x^0 \in \interior\left(\mathcal{K}\right)$, $z^0 \in \interior\left(\mathcal{K}^*\right)$, $y^0 \in \mathbb{R}^m$, $\tau^0 > 0$, $\kappa^0 > 0$, $\theta^0>0$. One strategy is to set $y^0 = 0$, $\tau^0 = \kappa^0 = \theta^0 = 1$. For $x^0$ and $z^0$, we will take the analytical centers of the respective barrier function of $\mathcal{K}$ (and equivalently that of $\mathcal{K}^*$). In other words, we first find a LHSCB for the product cone $\mathcal{K}$ as the sum of its parts using the following fact.
\begin{prop}
	Suppose $f_1, \cdots , f_N$ are LHSCB for proper cones $\mathcal{K}_1, \cdots, \mathcal{K}_N$ respectively, then $f: \mathcal{K}_1 \times\cdots\times \mathcal{K}_N \rightarrow \mathbb{R}$ defined by $f([x_1;\cdots; x_N]) = f_1(x_1) + \cdots + f_N(x_N)$ is a LHSCB for $\mathcal{K}_1 \times \cdots \times \mathcal{K}_N$.
\end{prop}

Since we have found analytic expressions for the LHSCB for the nonnegative orthant, the Lorentz cone, the exponential cone and its dual cone, we have found a LHSCB $f$ for the product cone $\mathcal{K}$.

\begin{align*}
x^0 = [x_1^0;\cdots;x_N^0] \in \left(\interior\left(\mathcal{K}_{\exp}\right)\right)^N,\ \
z^0 = [z_1^0;\cdots; z_N^0] \in \left(\interior\left(\mathcal{P}_{\exp}\right)\right)^N.
\end{align*}
We will adopt the initialization strategy for $x^0$ and $z^0$ in \cite{Akle_thesis}, which is to find $\iota^0 \in \mathcal{K}_{\exp}$ such that $\iota^0 =  -\tilde{g}(\iota)$ and set $x_i^0 = z_i^0 = \iota^0$, $i = 1,\cdots, N$. Such $\iota^0$ will also satisfy $\iota^0 \in \interior \left(\mathcal{P}_{\exp}\right)$ and $\iota^0 = -\tilde{g}^*(\iota^0)$. It turns out that $\iota^0 =   (-1.0151, 1.2590, 0.5560)^T$ sufficies. In other words, $\iota^0 \in \interior \left(\mathcal{K}_{\exp}\right)$ and $||\iota^0 + \tilde{g}(\iota)|| \approx 0$. Compute the auxillary parameters $\bar{b}$, $\bar{c}$, $\bar{g}$, $\bar{\alpha}$. Set the initial central-path parameter $\mu^0 = \theta^0$.

\subsection{A typical iteration}\label{A_typical_iteration}
Henthforth the current and next iterates are denoted as  $(x,y, \tau, z,\kappa, \theta)$ and  $(x^+, y^+ \tau^+, z^+,\kappa^+, \theta^+)$ respectively. Similarly we also use $(\cdot)^+$ to denote the updated values of the parameters for the next iteration. Similar to Algorithm 6 in Chapter 10 of \cite{Akle_thesis}, we set the \textit{central-path parameter} $\mu = \theta$,  the \textit{central-path proximity measure} \[\Omega(x,z,\tau,\kappa) = (\nu+1) \log\left(\frac{x^T z + \tau\kappa}{\nu+1}\right) + (\nu+1)+ f(x)+f^*(z) - \log(\tau) - \log(\kappa)\] 
and the \textit{neighborhood threshold} $\bar{\Omega} = \Omega(x^0,z^0,\tau^0,\kappa^0)+1$. 
Solve the following system for the \textit{predictor search direction} $(\Delta x, \Delta y, \Delta z, \Delta \tau, \Delta \kappa, \Delta \theta)$.
\begin{align}
& \begin{bmatrix}
0 & -A & b & -\bar b\ \\ 
A^T & 0 & -c & \bar c \\
-b^T & c^T& 0 & -\bar g \\
\bar b^T & -\bar c^T & \bar g & 0
\end{bmatrix}
\begin{bmatrix}
\Delta y \\ \Delta x \\ \Delta \tau \\ \Delta \theta
\end{bmatrix} + 
\begin{bmatrix}
0 \\ \Delta z \\ \Delta \kappa \\ 0 
\end{bmatrix} = \begin{bmatrix}
0 \\0\\0\\0
\end{bmatrix} \label{predictor_system_1} \\[1ex]
& \tau \Delta \kappa + \kappa \Delta \tau = - \tau \kappa \label{predictor_system_2} \\[1ex]
& \theta H^*(z)\Delta z + \Delta x = -x. \label{predictor_system_3}
\end{align}
Note that the above system \eqref{predictor_system_1} - \eqref{predictor_system_3} can be compactly written as $\bar G \Delta \bar x_p = \bar R_p$, where
\begin{align}
\bar G = \begin{bmatrix}
-A & 0 & 0 & b & 0 & -\bar b\ \\
0 & A^T & I & -c & 0 & \bar c \\
c^T & -b^T & 0 & 0 & 1 & -\bar g \\
-\bar c^T & \bar b^T & 0 & \bar g & 0 & 0 \\
0 & 0 & 0 & \kappa & \tau & 0 \\
I & 0 & \theta H^*(z) & 0 & 0 & 0
\end{bmatrix},\ \Delta \bar{x}_p = \begin{bmatrix}
\Delta{x}_p\\ \Delta{y}_p\\ \Delta{z}_p\\ \Delta{\tau}_p\\ \Delta{\kappa}_p\\ \Delta{\theta}_p
\end{bmatrix},\ \bar R_p= \begin{bmatrix}
0 \\ 0 \\ 0 \\ 0 \\-\tau\kappa \\ -x
\end{bmatrix}. \label{G_bar_etc_predictor_system_def}
\end{align} 

Set the \textit{maximum step-length} based on the predictor search direction and the neighborhood characterization
\[\alpha_p = \max\left\{ \alpha >0 \mid \Omega(x+\alpha \Delta x_p, z+\alpha \Delta z_p, \tau + \alpha \Delta \tau_p, \kappa + \alpha \Delta \kappa_p) \leq \bar{\Omega} \right\}. \]
Alternatively, one may find sufficiently large $\alpha_p>0$ such that $x + \alpha_p \Delta x_p \in \interior \left(\mathcal{K}_{\exp}\right)$, $z + \alpha_p \Delta z_p \in \interior \left(\mathcal{P}_{\exp}\right)$, $\tau + \alpha_p \Delta \tau_p > 0$, $\kappa + \alpha_p \Delta \kappa_p > 0$. Set $\sigma = \max\left\{(1-\alpha_p)^3, 0\right\}$. \\

Solve the following system for the (combined) search direction $(\Delta x, \Delta y, \Delta z, \Delta \tau, \Delta \kappa, \Delta \theta)$.
\begin{align}
& \begin{bmatrix}
0 & -A & b & -\bar b\ \\ 
A^T & 0 & -c & \bar c \\
-b^T & c^T& 0 & -\bar g \\
\bar b^T & -\bar c^T & \bar g & 0
\end{bmatrix}
\begin{bmatrix}
\Delta y \\ \Delta x \\ \Delta \tau \\ \Delta \theta
\end{bmatrix} + 
\begin{bmatrix}
0 \\ \Delta z \\ \Delta \kappa \\ 0 
\end{bmatrix} = \begin{bmatrix}
0\\0\\0\\0
\end{bmatrix} \label{combined_system_1}\\[1ex]
& \tau \Delta \kappa + \kappa \Delta \tau = - \tau \kappa + \sigma \theta - \Delta \tau_p \Delta \kappa_p \label{combined_system_2}\\[1ex]
& \mu H^*(z)\Delta z + \Delta x = -x - \sigma \theta g^*(z). \label{combined_system_3}
\end{align}
Note that similarly \eqref{combined_system_1} - \eqref{combined_system_3} can be written as $\bar G \Delta \bar x = \bar R$, where $\bar G$ is defined in \eqref{G_bar_etc_predictor_system_def} and 
\[\Delta \bar x =  \begin{bmatrix}
\Delta{x}\\ \Delta{y}\\ \Delta{z}\\ \Delta{\tau}\\ \Delta{\kappa}\\ \Delta{\theta}
\end{bmatrix},\ \bar R = \begin{bmatrix}
0\\0\\0\\0\\-\tau\kappa + \sigma\theta - \Delta\tau_p\kappa_p \\[0.8ex] -x - \sigma\theta g^*(z)
	\end{bmatrix}. \]
Set the \textit{step-length} based on the combined search direction and the neighborhood characterization
\[\alpha_c = \max\left\{ \alpha >0 \mid \Omega(x+\alpha \Delta x, z+\alpha \Delta z, \tau + \alpha \Delta \tau, \kappa + \alpha \Delta \kappa) \leq \bar{\Omega} \right\}.\]
Alternatively, one may find $\alpha_c>0$ such that $x + \alpha_c \Delta x \in \interior \left(\mathcal{K}_{\exp}\right)$, $z + \alpha_c \Delta z \in \interior \left(\mathcal{P}_{\exp}\right)$, $\tau + \alpha_c \Delta \tau > 0$, $\kappa + \alpha_c \Delta \kappa > 0$.
Set $\alpha' = 0.98 \alpha_c$ and the next iterate 
\[(x^+, y^+ \tau^+, z^+,\kappa^+, \theta^+) = (x,y, \tau, z,\kappa, \theta)+\alpha' (\Delta x, \Delta y, \Delta z, \Delta \tau, \Delta \kappa, \Delta \theta).\]
\subsection{Termination conditions}

\newpage
\appendix
\section{A simplified homogeneous self-dual model}
Below we describe a \textit{simplified} homogeneous self-dual embedding (SHSD) for (PD) and a path-following algorithm that solves (SHSD) and consequently solves or detects infeasibility of (PD). Consider the following feasibility problem
\begin{align*}
\begin{split}
& \min \,\, 0 \\
& \text{s.t.} \begin{bmatrix}
0 & A & -b \\ 
-A^T & 0 & c \\
b^T & -c^T& 0 
\end{bmatrix}
\begin{bmatrix}
y \\ x \\ \tau
\end{bmatrix} - 
\begin{bmatrix}
0 \\ z \\ \kappa 
\end{bmatrix} = 
\begin{bmatrix}
0 \\ 0 \\ 0
\end{bmatrix}\\
& x \in \mathcal{K},\ z \in \mathcal{K}^*,\ \tau \geq 0,\ \kappa\geq 0,\ y \in \mathbb{R}^m.
\end{split} \quad \quad \quad \text{(SHSD)}
\end{align*}
It can be shown that the above problem is self-dual (Lemma 1 in \cite{Skarjaa_and_Ye}). Similar to Proposition \ref{properties_HSD}, the following facts hold (Lemma 2 in \cite{Skarjaa_and_Ye}).
\begin{prop}\label{properties_SHSD}
Assume $(x,y,z,\tau,\kappa)$ solves (SHSD).
\begin{enumerate}
		\item One has $x^T z + \tau\kappa = 0$ (complimentarity).
		\item If $\tau>0$ then $(x,y,z)/\tau$ is an optimal solution to (PD). 
		\item If $\kappa>0$ then either $b^Ty>0$ or $c^Tx<0$ or both hold. 
		\subitem If $b^T y>0$ then (PD) is primal-infeasible.
		\subitem If $c^T x < 0$ then (PD) is dual infeasible.
	\end{enumerate}
\end{prop}
Next we describe the algorithm in moderate detail. For notational convenience, denote 
\[G = \begin{bmatrix}
0 & A & -b \\ 
-A^T & 0 & c \\
b^T & -c^T& 0 
\end{bmatrix}.\]
\subsection{Initialization} Given an initial point $(x^0, y^0, z^0, \tau^0, \kappa^0)$ such that $x^0 \in \interior\left(\mathcal{K}\right)$, $z^0 \in \interior\left(\mathcal{K}^*\right)$, $\tau>0$ and $\kappa>0$, calculate the residual of the linear constraints
\[R^0 =  G
\begin{bmatrix}
y^0 \\ x^0 \\ \tau^0
\end{bmatrix} - 
\begin{bmatrix}
0 \\ z^0 \\ \kappa^0
\end{bmatrix}.\]
Define $\mu^0 = \left((x^0)^T z^0 + \tau^0\kappa^0\right)/(\nu+1)$.  When $\mathcal{K}$ = $\left(\mathcal{K}_{\exp}\right)^N$ (only exponential cone constraints are present), one has $\nu = 3N$. Take a pair of barriers $f$ for $\mathcal{K}$ and $f^*$ for $\mathcal{K}^*$. Denote their gradients and Hessians as $g$, $g^*$ and $H$, $H^*$ respectively. For this algorithm, we take $f = \tilde{f}_{\exp}$ and $f^* = \tilde{f}_{\exp}^*$ (stacked $N$ times if necessary when necessary). It can be shown that for any $\mu \in (0,\mu^0]$, there exists a unique vector $\bar{x}(\mu) := (x_\mu, y_\mu, z_\mu, \tau_\mu, \kappa_\mu)$ that satisfies
\begin{align*}
\begin{split}
G \begin{bmatrix}
y \\ x \\ \tau
\end{bmatrix} - 
\begin{bmatrix}
0 \\ z \\ \kappa 
\end{bmatrix} = 
\mu R^0 \\[1ex]
 \tau \kappa = \mu \\[1ex]
 x - \mu g^*(z) = 0 \\[1ex]
x \in \mathcal{K},\ z \in \mathcal{K}^*,\ \tau \geq 0,\ \kappa\geq 0,\ y \in \mathbb{R}^m.
\end{split} \quad \quad \quad
\end{align*}
Define the \textit{central-path} parametrized by $\mu$ as $\Gamma = \left\{ \bar{x}(\mu) \mid \mu \in (0,\mu^0] \right\}$. It can be shown that as $\mu \rightarrow 0$, $\bar{x}(\mu)$ converges to a solution to (SHSD).
\subsection{A typical iteration}
We use $(\cdot)$ and $(\cdot)^+$ to denote the current and updated values of a varaible or parameter. First, set $\mu = \left(x^T z + \tau \kappa\right)/\left(\nu+1\right)$, calculate the current residual of the linear constraints
\[R = G \begin{bmatrix}
y \\ x \\ \tau
\end{bmatrix} - 
\begin{bmatrix}
0 \\ z \\ \kappa 
\end{bmatrix}\]
and solve the following system for the predictor search direction $(\Delta x_p, \Delta y_p, \Delta z_p, \Delta \tau_p, \Delta \kappa_p)$.
\begin{align}
\begin{split}
G\begin{bmatrix}
\Delta y_p \\ \Delta x_p \\ \Delta \tau_p
\end{bmatrix} - 
\begin{bmatrix}
0 \\ \Delta z_p \\ \Delta \kappa_p
\end{bmatrix} = -R \\[1ex]
\tau\Delta \kappa_p+\kappa\Delta \tau_p = -\tau\kappa \\[1ex]
\mu H^*(z)\Delta z_p + \Delta x_p = -x. 
\end{split}	 \label{shsd_predictor_system}
\end{align}
Note that we can write \eqref{shsd_predictor_system} compactly as $\bar G \Delta \bar{x}_p = \bar{R}$ where 
\begin{align} \label{G_bar_etc_def}
\bar{G} = \begin{bmatrix}
A & 0 &0 & -b & 0 \\
0 & -A^T & -I & c & 0 \\
-c^T & b^T & 0 & 0 & -1 \\
0 & 0 & 0 & \kappa & \tau \\
I & 0 & \mu H^*(z) & 0 & 0 
\end{bmatrix},\quad \Delta \bar{x}_p = \begin{bmatrix}
\Delta x_p \\ \Delta y_p \\ \Delta z_p \\ \Delta \tau_p \\ \Delta \kappa_p
\end{bmatrix},\quad \bar{R}_p = \begin{bmatrix}
-R \\ -\tau\kappa \\ -x
\end{bmatrix}.\end{align}

We will make use of the same central-path proximity measure $\Omega$ defined in Section \ref{A_typical_iteration} and take the threshold $\bar{\Omega} = \Omega\left(x^0, z^0, \tau^0, \kappa^0\right)+1$. Note that for any $x\in \interior\left(\mathcal{K}\right)$, $z\in \interior\left(\mathcal{K}^*\right)$, $\tau,\kappa > 0$, one has $\Omega(x,z,\tau,\kappa) \geq 0$. Furthermore, $\Omega(x,z,\tau,\kappa) = 0$ if and only if $(x,z,\tau,\kappa)$ is on the central-path. Find \[\alpha_{\max} = \max \left\{\alpha > 0 \mid \Omega(x+\alpha\Delta x_p,z+\alpha\Delta z_p,\tau+\alpha\Delta\tau_p,\kappa+\alpha\Delta\kappa_p)\leq \bar\Omega\right\}.\] Note that the maximum is attained due to the compactness of the set. Set $\sigma = \max \left\{ (1-\alpha_{\max})^3, 0 \right\}$. Solve the following system for the combined search direction $(\Delta x, \Delta y, \Delta z, \Delta \tau, \Delta \kappa)$.
\begin{align}
\begin{split}
G \begin{bmatrix}
\Delta y \\ \Delta x \\ \Delta \tau
\end{bmatrix} - 
\begin{bmatrix}
0 \\ \Delta z \\ \Delta \kappa
\end{bmatrix} = -\left(1-\sigma\right)R \\[1ex]
\tau\Delta \kappa+\kappa\Delta \tau = -\tau\kappa + \sigma \mu - \Delta \tau_p \Delta \kappa_p \\[1ex]
\mu H^*(z)\Delta z + \Delta x = -x - \sigma\mu g^*(z).
\end{split}	\label{shsd_corrector_direction}
\end{align}
Similarly, \eqref{shsd_corrector_direction} can be written compactly as $\bar G \Delta \bar x = \bar R$, where $\bar G$ is definedd This in \eqref{G_bar_etc_def} and 
\begin{align}\label{G_Bar_etc_2}
\Delta \bar{x} = \begin{bmatrix}
\Delta x \\ \Delta y \\ \Delta z \\ \Delta \tau \\ \Delta \kappa
\end{bmatrix},\quad \bar{R} = \begin{bmatrix}
-\left(1-\sigma\right)R \\ -\tau\kappa +\sigma \mu - \Delta \tau_p \Delta \kappa_p\\ -x - \sigma\mu g^*(z)
\end{bmatrix}.
\end{align}
Find $\alpha_{\max}' = \max \left\{\alpha > 0 \mid \Omega(x+\alpha\Delta x,z+\alpha\Delta z,\tau+\alpha\Delta\tau,\kappa+\alpha\Delta\kappa)\leq \bar\Omega\right\}$. Set the step-length $\alpha' = 0.98\alpha_{\max}'$. Update the iterate $(x^+,y^+,z^+, \tau^+, \kappa^+) = (x,y,z,\tau,\kappa) + \alpha' (\Delta x, \Delta y, \Delta z, \Delta \tau, \Delta \kappa)$. Repeat until a termination condition is met.
\subsection{Termination conditions}
We are interested in either a solution or a certificate of infeasibility of (PD). Similar to Section 5.4 in \cite{Skarjaa_and_Ye}, there are 3 possibilities. 
\begin{enumerate}
	\item We declare optimality (primal and dual feasibility with an approximate optimal solution found) if
	\begin{align}
	\left\| Ax-\tau b \right\|_{\infty} &\leq \epsilon \cdot \max \left\{1, \left\|[A,b]\right\|_{\infty}\right\} \label{P_termination}\\
	\left\|A^T y + z-c\tau\right\|_{\infty} &\leq \epsilon \cdot \max \left\{1, \left\|A^T, I , -c\right\|_{\infty}\right\}\label{D_termination}\\
	\left|c^T x/\tau - b^T y/\tau\right|  &\leq \epsilon\cdot\left(1+\left|b^T y/\tau\right|\right).\label{A_termination}
	\end{align}
	In this case, the approximate optimal solution $(x,y,z)/\tau$ is returned.
	\item We declare primal and/or dual infeasibility if \eqref{P_termination}, \eqref{D_termination} and 
	\begin{align}
	\left|-c^T x+b^T y - \kappa \right| &\leq \epsilon\cdot \max \left\{1, \left\|\left[-c^T, b^T, 1\right]\right\|_{\infty}\right\} \label{G_termination}\\
	\tau &\leq \epsilon \cdot 10^{-2} \cdot \left\{1,\kappa\right\}\label{T_terminal}
	\end{align}
	hold. If $b^T y>0$ ($c^T x<0$, respectively), the problem is primal infeasible (dual infeasible, respectively).
	\item We declare that the problem is ill-posed if 
	\begin{align*}
	\kappa &\leq \epsilon \cdot 10^{-2}\cdot \min \left\{1,\tau\right\}\\
	\mu &\leq \epsilon \cdot 10^{-2}\cdot \mu^0.
	\end{align*}
\end{enumerate}

\newpage
\bibliography{references}{}
\bibliographystyle{plain}
\end{document}