\documentclass[10pt]{article}
\usepackage{graphicx,amsmath,amsthm, amssymb,setspace}
\usepackage[utf8]{inputenc}
\usepackage[a4paper, total={6in, 8.5in}]{geometry}
\usepackage{cite}

\theoremstyle{definition}
\newtheorem{defin}{Definition}
\newtheorem{assumption}{Assumption} 
\theoremstyle{plain}
\newtheorem{lemma}{Lemma}%[section]
\newtheorem{example}{Example}
\newtheorem{prop}{Proposition}
\newtheorem{thm}{Theorem}
\newtheorem{cor}{Corollary}

\def\DM{\protect{$\cal{DM}$}}
\def\interior{\protect{\textnormal{ri}}}
\def\relint{\protect{\textnormal{ri}}}
\def\closure{\protect{\textnormal{closure}}}
\def\rank{\protect{\textnormal{rank}}}
\def\diagonal{\protect{\textnormal{diag}}}

\title{Design and implementation of a homogeneous interior-point method for conic programming involving exponential cone constraints}
\author{Yuan GAO}
\begin{document}
\maketitle

\begin{abstract}
We introduce the concept of exponential cone, its basic mathematical properties and designed a homogeneous interior-point method for sonic programming involving exponential cone constraints. We tested the implementation on stochastic and robust optimization problems. Techniques of modeling with exponential cone are also discussed.
\end{abstract}

\section{Definitions and preliminaries}
In order to begin the discussion on properties of the exponential cone and the homogeneous interior-point method, we summarize the relevant concepts and facts for easy reference. For a more detailed survey on (non-symmetric) conic programming and interior-point methods, see \cite{Robert_thesis} and \cite{Akle_thesis}.\\

Denote $\mathbb{R}_+ = \left\{x \mid x\in \mathbb{R}, x\geq 0\right\}$ and $\mathbb{R}_{++} = \left\{x \mid x\in \mathbb{R}, x> 0\right\}$. For matrices $M_1, \cdots, M_N$, denote $\diagonal(M_1, \cdots, M_N)$ the block-diagonal matrix with $M_j$ as diagonal blocks. The relative interior of a set $\mathcal{S} \subset \mathbb{R}^n$ is denoted as $\interior\left(\mathcal{S}\right)$. A subset $\mathcal{K}$ of an Euclidean space $\mathbb{R}^n$ is a \textit{(pointed) convex cone} if (1) $\mathbf{0} \in \mathcal{K}$, (2) for any $\alpha, \beta \in \mathbb{R}_+$ and $x,y \in \mathcal{K}$, one has $\alpha x + \beta y \in \mathcal{K}$, and (3) the only linear subspace of $\mathbb{R}^n$ contained in $\mathcal{K}$ is $\left\{0\right\}$. A \textit{proper cone} is a convex cone that is pointed, closed and has non-empty relative interior in the usual Euclidean space topology.\\

For a convex cone $\mathcal{K} \in \mathbb{R}^n$, its \textit{dual cone} is defined as 
$\mathcal{K}^* = \left\{y\in \mathbb{R}^n \mid x^T y\geq 0, \forall x \in \mathcal{K} \right\}$. A proper cone $\mathcal{K}$ is called \textit{self-dual} if $\mathcal{K}^* = \mathcal{K}$. It can be shown that for a proper cone $\mathcal{K} \in \mathbb{R}^n$, its dual cone $\mathcal{K}^*$ is also a proper cone and $(\mathcal{K}^*)^* = \mathcal{K}$ (Section 2.6. in \cite{Boyd_Vander_Convex_Opt_Book}). \\

For our purpose, we define the \textnormal{Lorentz cone} of dimension $n\geq 2$ as
\[\mathcal{Q}_n = \left\{ x \in \mathbb{R}^n \mid x_1 \geq \sqrt{x_2+\cdots+x_n} \right\}.\]
It can be easily seen that both the positive orthant and the Lorentz cone are self-dual. The positive orthant, the Lorenz cone and the positive semidefinite cone $\mathcal{S}^n_+ = \left\{ X \in \mathcal{S}^{n} \mid X\succeq 0 \right\}$, (where $\mathcal{S}^n$ denotes the symmetric matrices in $\mathbb{R}^{n\times n}$) are all proper and self-dual. They are sometimes referred to as \textit{symmetric cones}. \\

Next we define the exponential cone and give analytic expressions of it and its dual cone.

\begin{defin}
	Let $\mathcal{K}^0_{\exp} = \left\{(x, y, z) \in \mathbb{R}^3 \mid y \geq 0, z > 0, \exp\left(\dfrac{x}{z}\right) \leq \dfrac{y}{z}\right\}$
	and define the \textit{exponential cone} as
	$\mathcal{K}_{\exp} = \textnormal{closure}\left(K^0_{\exp}\right)$. Let $\mathcal{P}^0_{\exp} = \left\{(u,v,w) \in \mathbb{R}^3 \mid u<0, v \geq 0, \exp\left(\dfrac{w}{u}\right)\leq -\dfrac{e\cdot v}{u} \right\}$
	and define $\mathcal{P}_{\exp} = \textnormal{closure} \left(\mathcal{P}^0_{\exp}\right)$,
	where $e$ denotes the base of natural logarithm. 
\end{defin}
\begin{prop}\label{K_exp=K0_exp_union_something}
	One has $\mathcal{K}_{\exp} = K^0_{\exp} \cup \left[\left(-\mathbb{R}_+\right) \times \mathbb{R}_+ \times \{0\} \right]$, $\mathcal{P}_{\exp} = \mathcal{P}^0_{\exp} \cup \{0\} \times \mathbb{R}_+ \times \mathbb{R}_+$ and $ (\mathcal{K}_{\exp})^* = \mathcal{P}_{\exp}$.
\end{prop}
Note that $\mathcal{K}_{\exp}$ is not symmetric. \\

We will be primarily working with the above three types of proper cones, namely, the positive orthants $\mathbb{R}_+^{n}$, the Lorentz cone $\mathcal{Q}^m$ and the exponential cone $\mathcal{K}_{\exp}$. In other words, the interior-point method we present deals with problems with a conic constraint $s \in \mathcal{K}$, where $\mathcal{K}$ is a Cartesian product of arbitrary number of these three types of cones.\\

In theory, all polynomial-time interior-point methods for conic programming problems require a well-defined and computable (up to the Hessian) barrier function for the cone.

\begin{defin}
	Let $\mathcal{K} \subset \mathbb{R}^n$ be a closed convex set with $\textnormal{int}\left(\mathcal{K}\right) \neq \emptyset$, and $f: \textnormal{int} \left(\mathcal{K}\right) \rightarrow \mathbb{R}$ be strictly convex. The function $f$ is called a \textit{self-concordant barrier} for $\mathcal{K}$  if 
	\begin{enumerate}
		\item (barrier property) for any sequence of points $\{x_n\}$ such that $\lim x_n \in \mathcal{K}\backslash \textnormal{int}\left(\mathcal{K}\right)$, one has $\lim f(x_n) = \infty$,
		\item (differentiability) $f$ has continuous third-order mixed partial derivatives, and
		\item (self-concordance) for any $x \in \textnormal{int}\left(\mathcal{K}\right)$ and $v \in \mathbb{R}^n$, the function $\phi(t) = f(x+tv)$ satisfies $|\phi ''' (t)|\leq M_f \left(\phi '' (t)\right)^{2/3}$ for some constant $M_f \geq 0$ and all $t$ such that $tv \in \textnormal{int}\left(\mathcal{K}\right)$.
	\end{enumerate}
\end{defin}

\begin{defin}
	Let $\mathcal{K}$ be a proper cone. The function $f: \textnormal{int}\left(\mathcal{K}\right)\rightarrow \mathbb{R}$ is called a logarithmically homogeneous self-concordant barrier (LHSCB) for $\mathcal{K}$ with parameter $\nu$ if $f$ is a self-concordant barrier for $\mathcal{K}$ and for all $x \in \textnormal{int}\left(\mathcal{K}\right)$ and $t>0$, one has 
	\[f(tx) = f(x) - \nu \log t.\]
\end{defin}

Below is an important property of logarithmically homogeneous self-concordant barriers (see Theorem 4.3.4 in \cite{Akle_thesis}).
\begin{prop} \label{conjugate_of_LHSCB_is_LHSCB_for_dual}
	Let $\mathcal{K}$ be a proper cone and $f$ a LHSCB for $\mathcal{K}$ with parameter $\nu$. The \textnormal{conjugate barrier} of $f$, denoted as $f^*$, defined on $\textnormal{int}(\mathcal{K}^*)$ by 
	\[f^*(s) = \sup \left\{-s^Tx -f(x) \mid x\in \textnormal{int}\left(\mathcal{K}\right)  \right\}\]
	is a LHSCB for $\mathcal{K}^*$ with parameter $\nu$. Furthermore, one has $(f^*)^* = f$.
\end{prop}
Note that the definition of conjugate barrier in this context is slightly different from the definition of convex conjugate adopted in standard references of convex analysis. \\

We list some useful barriers for the important types of cones.

\begin{prop} \label{barriers_for_linear_and_lorentz_cone}
	\textnormal{(Section 2 of \cite{CVX})} The function 
	\[f_l(x) =-\sum_{i=1}^n \log x_i\]
	is a LHCSB for the nonnegative orthant $\mathbb{R}_+^{n}$ with $\nu = n$. Its gradient and Hessian are
	\[\nabla g_l(x) = f_l(x)= \begin{bmatrix}
	-\dfrac{1}{x_1} \\[2ex] \vdots \\[2ex] -\dfrac{1}{x_n} \\[1ex]
	\end{bmatrix},\quad 
	H_l(x) = \nabla^2 f_l(x) = \begin{bmatrix}
	\dfrac{1}{x_1^2} & 			  &				 			 \\[2ex] 
							& \ddots &						    \\[2ex] 
							&			 &	\dfrac{1}{x_n^2} \\[1ex]
	\end{bmatrix}. \]
	The function 
	\[f_q(x) = -\dfrac{1}{2}\log\left(x_1^2 - ||\tilde{x}||^2\right)\]
	where $\tilde{x} = \left(x_2,\cdots,x_n\right)^T$ and $||\cdot|| = ||\cdot||_2$ is a LHSCB for $\mathcal{Q}_n$ with $\nu = 2$. The gradient and Hessian of $f_q$ are
	\[g_q(x) = - \dfrac{1}{x^T J x} Jx, \quad H_q(x) =  \dfrac{1}{(x^T J x)^2}\left(2Jxx^T J - (x^T J x)J\right) \]
	where $J = \begin{bmatrix}
	1 & \\ & -I_{n-1}
	\end{bmatrix}$.
\end{prop}

In \cite{Akle_thesis}, the author listed two different pairs of conjugate barriers (LHSCB) for the exponential cone and its dual cone.

\begin{defin}
	The Wright Omega function $\omega: \mathbb{R} \rightarrow \mathbb{R}_{++}$ is defined as the unique solution to the equation 
	\[\omega(\beta) + \log \omega(\beta) = \beta \]
	for $\beta \in \mathbb{R}$.
\end{defin}

\begin{prop}
	The function $f_{\exp}: \textnormal{int}\left(\mathcal{K}_{\exp}\right) \rightarrow \mathbb{R}$ defined by 
	\[f_{\exp}(x,y,z) = -\log\left(z\log \left(\dfrac{y}{z}\right)-x\right) - \log y - \log z\]
	is a LHSCB for $\mathcal{K}_{\exp}$  with $\nu = 3$. 	Its conjugate $f_{\exp}^*: \textnormal{int}\left(\mathcal{P}_{\exp}\right) \rightarrow \mathbb{R}$, which is a LHSCB for $\left(\mathcal{K}_{\exp}\right)^* = \mathcal{P}_{\exp}$ with $\nu = 3$, takes the following expression 
	\[f_{\exp}^*(u,v,w) = -2 \log(-u) -\log v -\log\left(\dfrac{(1-\bar{\omega})^2}{\bar{\omega}}\right) - 3 \]
	where 
	\[\bar{\omega} = \omega\left(2-\dfrac{w}{u} - \log (-u) + \log v \right). \]
\end{prop}

Note that the dual barrier $f_{\exp}^*$ above has a slightly more complicated expression than the primal barrier $f_{\exp}$. It is not too difficult to work out another pair of conjugate barrier functions where the dual barrier takes a slightly simpler expression instead. In fact, there exists an invertible linear transformation $B: \mathbb{R}^3 \rightarrow \mathbb{R}^3 $ such that $B\left(\textnormal{int} \left(\mathcal{K}_{\exp}\right)\right) = \textnormal{int} \left(\mathcal{P}_{\exp}\right)$, which is given by the matrix
\[ B =  \begin{bmatrix}
     &    & -1 \\[1ex]
     &  \dfrac{1}{e} &     \\[1ex]
 -1 &    & 
\end{bmatrix}. \]
As such, $\tilde{f}_{\exp}(x,y,z) = f^*_{\exp}(B (x,y,z))$ is a LHSCB for $\mathcal{K}_{\exp}$ and $\tilde{f}_{\exp}^*(u,v,w) = f_{\exp}(B^{-1}(u,v,w))$ is its conjugate barrier, which is a LHSCB for $\mathcal{P}_{\exp}$. Note that by the definition of conjugate barrier and the property of LHSCB, we may also take $\tilde{f}_{\exp} + \beta$ and $ \left(\tilde{f}_{\exp} + \beta\right)^* = \tilde{f}^*_{\exp} - \beta $ as the LHSCBs for $\mathcal{K}_{\exp}$ and $\mathcal{P}_{\exp}$, respectively, for any $\beta \in \mathbb{R}$.

\begin{prop}
	The function $\tilde{f}_{\exp}: \textnormal{int}\left(\mathcal{K}_{\exp}\right)\rightarrow \mathbb{R}$ defined by
	\[\tilde{f}_{\exp}(x,y,z) = -2 \log z - \log y  - \log \left(\dfrac{(1-\bar{\omega})^2}{\bar{\omega}}\right) - 3 \]
	where 
	\[\bar{\omega} = \omega\left(1-\dfrac{x}{z} - \log z - \log y\right) \]
	is a LHSCB for $\mathcal{K}_{\exp}$ with $\nu = 3$. Its conjugate $\tilde{f}_{\exp}^*: \textnormal{int}\left(\mathcal{P}_{\exp}\right) \rightarrow \mathbb{R}$, which is a LHSCB for $\left(\mathcal{K}_{\exp}\right)^* = \mathcal{P}_{\exp}$ with $\nu=3$, takes the following expression 
	\[\tilde{f}_{\exp}^*(u,v,w) = -\log\left(-t\right) - \log (-u) - \log v\]
	where $r = \log \left(-v/u\right)$ and $t=u-w+ur$.  Furthermore, the gradient and Hessian of the dual barrier at $(u,v,w)^T \in \interior\left(\mathcal{P}_{\exp}\right)$ take the following expressions \\
	\begin{align*}
	\tilde{g}^*\left((u,v,w)^T\right) &= \nabla \tilde{f}^*_{\exp}(u,v,w) =  
	\begin{bmatrix}
	-\dfrac{r}{t} - \dfrac{1}{u} \\[2ex]
	-\dfrac{1}{v} - \dfrac{u}{vt} \\[2ex]
	\dfrac{1}{t} \\[1ex]
	\end{bmatrix}, \\ \\
	\tilde{H}^*\left((u,v,w)^T\right) &= \nabla^2 \tilde{f}^*_{\exp}(u,v,w) =  
	\begin{bmatrix}
	\dfrac{1}{ut} + \dfrac{r^2}{t^2}+ \dfrac{1}{u^2} & \dfrac{ur}{vt^2} - \dfrac{1}{vt} & -\dfrac{r}{t^2} \\[2ex]
	\dfrac{ur}{vt^2} - \dfrac{1}{vt}  & \dfrac{1}{v^2}+\dfrac{u}{v^2t} + \dfrac{u^2}{v^2t^2} & -\dfrac{u}{vt^2} \\[2ex]
	-\dfrac{r}{t^2}	& -\dfrac{u}{vt^2} & \dfrac{1}{t^2} \\[1.5ex]
	\end{bmatrix}.
	\end{align*}
\end{prop}
Note that once we obtain the expressions of the LHSCB, their gradients and Hessians for the positive orthant, the Lorentz cone and the exponential cone, we can easily construct LHSCB, their gradients and Hessians for any Cartesian product of these cones through vertical and block-diagonal concatenation.
\begin{prop}
	Suppose $f_j$ are $\nu_j$-LHSCB for proper cones $\mathcal{K}_j$, $j = 1,\cdots, N$ respectively, then $f: \mathcal{K}_1 \times\cdots\times \mathcal{K}_N \rightarrow \mathbb{R}$ defined by $f([x_1;\cdots; x_N]) = f_1(x_1) + \cdots + f_N(x_N)$ is a $\nu$-LHSCB for $\mathcal{K}_1 \times \cdots \times \mathcal{K}_N$ with $\nu = \sum_{j=1}^N\nu_j$. Furthermore, $\nabla f = [\nabla f_1; \cdots; \nabla f_N]$ and $\nabla^2 f = \diagonal(\nabla^2 f_1, \nabla^2 f_2, \cdots, \nabla^2 f_N)$.
\end{prop}


\section{The standard form, homogeneous self-dual embedding and central path}
For different purposes, various standard forms of conic programming have been used. In this paper, we consider the following pair of primal and dual problems
\begin{align}
\begin{split} 
\text{Primal:} \quad &\min\,\, c^Tx\\ 
&\textnormal{s.t.} \,\, Ax=b,\ x\in \mathcal{K} \\
\text{Dual:}  \quad &\max\,\, b^Ty \\
&\textnormal{s.t.} \,\, A^Ty+z=c,\ s\in\mathcal{K}^*,\ y \in \mathbb{R}^m \\
\end{split} &\text{(PD)} \nonumber
\end{align}
where $c,x \in \mathbb{R}^n$, $A\in \mathbb{R}^{m\times n}$, $b\in \mathbb{R}^m$ and $\mathcal{K} \subset \mathbb{R}^n$ is a proper cone. Without loss of generality, we further assume $m\leq n$ and $\text{rank}(A) = m$. By the generalized Slater's condition (see \cite{Boyd_Vander_Convex_Opt_Book}), if there exist
$x \in \text{int} \left(\mathcal{K}\right)$ such that $Ax=b$ and $z \in \interior \left(\mathcal{K}^*\right)$ such that $A^Ty+z=c$,
then strong duality holds for (PD). In this case, any primal-dual optimal solution $(x,y,s)$ must satisfy the following KKT system
\begin{align}\label{KKT_for_PD}
\begin{split}
Ax-b=0& \\
A^Ty+z-c=0& \\
x^Tz=0& \\
x\in\mathcal{K},\ z\in \mathcal{K}^*,\ y\in\mathbb{R}^m& 
\end{split}
\end{align}

We introduce the (full) \textit{homogeneous self-dual embedding} of (PD), which is similar to (25) in \cite{SDPT3_2010} and (27) in \cite{CVX},
\begin{align*}
\begin{split}
& \min \,\, \bar{\alpha}\theta \\
& \text{s.t.} \begin{bmatrix}
0 & -A & b & -\bar b\ \\ 
A^T & 0 & -c & \bar c \\
-b^T & c^T& 0 & -\bar g \\
\bar b^T & -\bar c^T & \bar g & 0
\end{bmatrix}
\begin{bmatrix}
y \\ x \\ \tau \\ \theta
\end{bmatrix} + 
\begin{bmatrix}
0 \\ z \\ \kappa \\ 0 
\end{bmatrix} = 
\begin{bmatrix}
0 \\ 0 \\ 0 \\ \bar \alpha
\end{bmatrix}\\
& x \in \mathcal{K},\ z \in \mathcal{K}^*,\ \tau \geq 0,\ \kappa\geq 0,\ y \in \mathbb{R}^m,\ \theta \in \mathbb{R}, 
\end{split} \quad \quad \quad \text{(HSD)}
\end{align*}
where the auxillary parameters $\bar b, \bar c, \bar g$ and $\bar \alpha$ are determined by a given $(x^0, y^0, z^0, \tau^0, \kappa^0, \theta^0)$ such that $x^0 \in \interior \left(\mathcal{K}\right)$, $z^0 \in \interior \left(\mathcal{K}^*\right)$, $\tau^0, \kappa^0, \theta^0 > 0$, namely,
\begin{align*}
\bar b = \dfrac{1}{\theta^0}\left(b\tau^0 - Ax^0\right),\quad\quad  \bar c = \dfrac{1}{\theta^0}\left(c\tau^0 - A^Ty^0 - z^0\right), \\ 
\bar g = \dfrac{1}{\theta^0}\left(c^T x^0 - b^T y + \kappa\right), \quad\quad  \bar \alpha = \dfrac{1}{\theta^0}\left((x^0)^T z^0 + \tau^0\kappa^0\right).
\end{align*}

The properties of (HSD) are summarized in the following proposition.
\begin{prop}\label{properties_HSD} \textnormal{(Lemma 1 in \cite{Freund_behavior_HSD})}
	For any given $(x^0, y^0, z^0, \tau^0, \kappa^0, \theta^0)$ such that $x^0 \in \interior \left(\mathcal{K}_{\exp}\right)$, $z^0 \in \interior \left(\mathcal{P}_{\exp}\right)$ and $\tau^0, \kappa^0, \theta^0 > 0$, the auxiliary parameters $\bar{b}$, $\bar{c}$, $\bar{g}$, $\bar{\alpha}$ and hence the problem (HSD) are well-defined. One has $\bar{\alpha}>0$. Further more, the following facts hold.
	\begin{enumerate}
		\item The problem (HSD) is \textnormal{self-dual}. In other words, the dual of the problem is equivalent to itself. 
		\item $(x,y,z,\tau,\kappa, \theta) = (x^0,y^0,z^0, \tau^0,\kappa^0, \theta^0)$ is a strictly feasible (primal and dual) solution.
		\item The optimal objective is always 0. 
		\item Assume the solution $(x,y, \tau, z,\kappa, \theta)$ is feasible. One has $\theta\geq 0$ and $x^T z + \tau \kappa = \bar{\alpha} \theta$. Furthermore, the solution is optimal if and only if $\theta=0$, in which case one has $x^T z = \tau\kappa = 0$.
		\item Assume $(x,y, \tau, z,\kappa, 0)$ is an optimal solution. If $\tau>0$ then $(x,y,z)/\tau$ is an optimal solution to (PD). If $\kappa>0$ then either $b^Ty>0$ or $c^Tx<0$ or both hold. 
		\subitem If $b^T y>0$ then (PD) is primal-infeasible.
		\subitem If $c^T x < 0$ then (PD) is dual infeasible.
		\item \textnormal{(Proposition 3 in \cite{Freund_behavior_HSD})} For any $\epsilon \geq 0$, there exists a feasible solution of (HSD) with objective value equal to $\epsilon$.
	\end{enumerate}
\end{prop} 
Note that if $(x,y,z,\tau,\kappa,0)$ is an optimal solution to (HSD) with $\tau=\kappa=0$, no conclusion can be made regarding (PD). \\

Next we introduce the concept of \textit{central path}, which is essential in developing a path-following algorithm for solving (HSD). First we need a simple lemma which is a consequence of the properties of $LHSCB$ (see, e.g. (2.43) in \cite{Robert_thesis}).
\begin{lemma}\label{x^plus_mu_g_dual_z_equals_0}
	Let $\mathcal{K}\in \mathbb{R}^n$ be a proper cone, $\mathcal{K}^*$ its dual cone with $\nu$-LHSCB $f^*$. Denote $g^* = \nabla f^*$. For any $x\in \interior\left(\mathcal{K}\right)$, $z\in \interior\left(\mathcal{K}^*\right)$ and $\mu > 0$ such that $x + \mu g^*(z) = 0$, one has $x^T z = \nu \mu$.
\end{lemma}
Now we formally define the central path parametrized by $\mu > 0$ in the following proposition. The proof can be found in \cite{Akle_thesis}.
	\begin{prop}
	With the same setting as Lemma \ref{x^plus_mu_g_dual_z_equals_0}, for any $\mu > 0$, there exists unique $\left(x, y, z, \tau, \kappa, \theta\right)$ with $x \in \interior\left(\mathcal{K}\right)$, $z \in \relint\left(\mathcal{K}^*\right)$, $\tau > 0$, $\kappa > 0$ that solves the following linear system
	\begin{align}\label{central^path_mu}
	\begin{split}
	&  \begin{bmatrix}
	0 & -A & b & -\bar b\ \\ 
	A^T & 0 & -c & \bar c \\
	-b^T & c^T& 0 & -\bar g \\
	\bar b^T & -\bar c^T & \bar g & 0
	\end{bmatrix}
	\begin{bmatrix}
	y \\ x \\ \tau \\ \theta
	\end{bmatrix} + 
	\begin{bmatrix}
	0 \\ z \\ \kappa \\ 0 
	\end{bmatrix} = 
	\begin{bmatrix}
	0 \\ 0 \\ 0 \\ \bar \alpha
	\end{bmatrix}\\
	& x + \mu g^*\left(z\right) = 0\\
	& \tau \kappa = \mu.
	\end{split}
	\end{align}
\end{prop}
Denote the above unique solution $(x,y,z,\tau,\kappa,\theta)$ as $\bar{x}_{\mu}$. The set $\left\{\bar{x}_{\mu} \right\}_{\mu > 0}$ is termed \textit{central path}. It can be shown that as $\mu \rightarrow 0$, $\bar{x}_{\mu}$ converges to a KKT point of (PD) (a solution of \eqref{KKT_for_PD}). \\ 

For $(x,y,z,\tau, \kappa,\theta)$ with $x \in \interior\left(\mathcal{K}\right)$, $z \in \relint\left(\mathcal{K}^*\right)$, $\tau > 0$, $\kappa > 0$ and $\mu>0$, define the \textit{predictor search direction} $\Delta{\bar{x}^p}$ as the solution to the following linear system (where $\Delta v$ and $\Delta v^p$ have the same dimension as $v$)
\begin{align}\label{predictor_system_mu}
\begin{split}
&  \begin{bmatrix}
0 & -A & b & -\bar b\ \\ 
A^T & 0 & -c & \bar c \\
-b^T & c^T& 0 & -\bar g \\
\bar b^T & -\bar c^T & \bar g & 0
\end{bmatrix}
\begin{bmatrix}
\Delta y^p \\ \Delta x^p \\ \Delta \tau^p \\ \Delta \theta^p
\end{bmatrix} + 
\begin{bmatrix}
0 \\ \Delta z^p \\ \Delta \kappa^p \\ 0 
\end{bmatrix} = 
\begin{bmatrix}
0 \\ 0 \\ 0 \\ 0
\end{bmatrix}\\
& \Delta x^p + \mu H^*\left(z\right) \Delta z^p = -x \\
& \tau \Delta{\kappa}^p + \kappa \Delta{\tau}^p = -\tau\kappa.
\end{split}
\end{align}
and the \textit{combined search direction} $\Delta \bar x$ as the solution to the following linear system
\begin{align}\label{combined_system_mu}
\begin{split}
&\begin{bmatrix}
0 & -A & b & -\bar b\ \\ 
A^T & 0 & -c & \bar c \\
-b^T & c^T& 0 & -\bar g \\
\bar b^T & -\bar c^T & \bar g & 0
\end{bmatrix}
\begin{bmatrix}
\Delta y \\ \Delta x \\ \Delta \tau \\ \Delta \theta
\end{bmatrix} + 
\begin{bmatrix}
0 \\ \Delta z \\ \Delta \kappa \\ 0 
\end{bmatrix} = 
\begin{bmatrix}
0 \\ 0 \\ 0 \\ 0
\end{bmatrix} \\ 
&\Delta{x} + \mu H^*(z)\Delta{z} = -x - \sigma \mu g^*(z) \\
& \tau \Delta \kappa + \kappa \Delta\tau = -\tau\kappa + \sigma \mu
\end{split}
\end{align}
where $\sigma \in \left[0,1\right]$ is a chosen combination parameter. Note that \eqref{predictor_system_mu} is in fact \eqref{combined_system_mu} with $\sigma = 0$.\\

If we write \eqref{central^path_mu} as $\Phi(\bar{x}, \mu) = 0$, where $\Phi: \mathbb{R}^{2n+m+3}\times \mathbb{R}\rightarrow \mathbb{R}^{2n+m+3}$ is a smooth vector-valued map. Viewing $\bar{x} = \bar{x}_\mu$ as a vector-valued function of $\mu$, by the Implicit Function Theorem, it can be shown that when $\bar{x} = \bar{x}_\mu$ for some $\mu > 0$, the direction $\Delta{x}^p$ defined by \eqref{predictor_system_mu} is tangent to the central path. In other words, $\Delta x^p = -\mu\cdot  \bar x_\mu'$, where $\bar x_\mu'$ denotes the derivative of $\bar x_\mu$ with respect to $\mu$ (differentiated component-wise). \\

For $\bar x = (x,y,z,\tau,\kappa, \theta) \in \bar K := \relint\left(\mathcal{K}\right) \times \mathbb{R}^m \times \relint\left(\mathcal{K}^*\right)\times \mathbb{R}_+^2 \times \mathbb{R}$ and $\mu > 0$, $\Delta \bar x$ defined by  \eqref{combined_system_mu} with $\sigma = 0$ will be the same as $\Delta x^p$ defined by \eqref{predictor_system_mu}, while \eqref{combined_system_mu} with $\sigma = 1$ gives $\Delta x^{corr}$ known as the \textit{centering search direction}. The term arises since it can be shown that moving along this direction decreases the \textit{central path proximity measure} of the iterate defined as 
\[\Omega(\bar x) = (\nu+1) \log\left(\frac{x^T z + \tau\kappa}{\nu+1}\right) + (\nu+1)+ f(x)+f^*(z) - \log(\tau) - \log(\kappa).\] 
It can be shown that for any $\bar x \in \bar K$, $\Omega (\bar x) \geq 0$, and $\bar x $ lies on the central path if and only if $\Omega(\bar x)=0$, in which case if \eqref{combined_system_mu} with $\sigma = 1$ gives a centering direction $\Delta \bar x = 0$. For $\sigma \in \left(0,1\right)$, \eqref{combined_system_mu} gives $\Delta \bar x = (1-\sigma) \Delta x^p + \sigma \Delta x^{corr}$, a combination of the two directions. \\

For implementation purpose, we will adopt the standard form in \cite{SDPT3_2010} which can be written in the form of (PD). Specifically, we consider the following pair of primal and dual problem
\begin{align*}
\begin{split}
\text{Primal:}\quad &\min\,\, \sum_{i=1}^N c_i^Tx_i\\
& \text{s.t.}\,\, \sum_{i=1}^N A_i x_i = b \\
&\quad\quad x_i \in K_i,\ \forall i \\[1ex] 
\text{Dual:} \quad &\max\,\, b^T y\\
& \text{s.t.}\,\, A_i^T y + z_i = c_i, \ \forall i \\
&\quad\quad y \in \mathbb{R}^m,\ z_i \in K_i^*, \forall i \\[1ex]
\end{split} \quad\quad\quad\quad\quad\quad\quad \text{(PD$'$)}
\end{align*}
where $x_i, c_i \in \mathbb{R}^{n_i}$, $A_i \in \mathbb{R}^{m\times n_i}$, $b \in \mathbb{R}^m$ and $n = \sum_{i=1}^N n_i \geq m$. Each $K_i$ is one of the following: (i) the nonnegative orthant $\mathbb{R}_+^{n_i}$, (ii) product of Lorentz cones $\mathcal{Q}^{q_1}\times \cdots \times \mathcal{Q}^{q_{k_i}}$, $\sum_{j=1}^{k_i} q_j = n_i$, (iii) product of the exponential cone  $\left(\mathcal{K}_{\exp}\right)^{k_i}$, $3k_i = n_i$ or (iv) $\mathbb{R}^n_i$. Note that we define (which is consistent with the definition of dual cone) $\left(\mathbb{R}^k\right)^* = \left\{ y \in \mathbb{R}^k \mid y^T x \geq 0,\ \forall x \in \mathbb{R}^k  \right\} = \left\{0\right\}^k$. To write (PD$'$) into (PD), one simply let
\[  A = \begin{bmatrix} A_1,\ \hdots,\  A_N \end{bmatrix},\ \
x = \begin{bmatrix} x_1 \\ \vdots\\ x_N \end{bmatrix},\ \ 
c = \begin{bmatrix} c_1 \\ \vdots \\c_N \end{bmatrix},\ \
z = \begin{bmatrix} z_1 \\ \vdots \\ z_N \end{bmatrix},\ \ \mathcal{K} = K_1 \times \cdots \times K_N,\ \ \mathcal{K}^* = K_1^* \times \cdots \times K_N^*.\]

For notational convenience, vertical concatenation of matrices (or vectors) of appropriate dimensions $(M_1^T,\ M_2^T,\ \cdots,\ M_L^T)^T$ will occasionally be denoted $[M_1; \cdots ; M_L]$.

\section{A homogeneous interior-point algorithm}
Next we describe the algorithm for solving (HSD) (and hence find either a solution to (PD) or certificates of infeasibility) in detail. Henceforth the gradients of the barriers for $\mathcal{K}$ and $\mathcal{K}^*$ will be denoted as $g$ and $g^*$ (in particular, $\mathcal{K}_{\exp}$ and $\mathcal{P}_{\exp}$) respectively, and the Hessians $H$ and $H^*$ respectively.
\subsection{Initialization}

Suppose one has a problem in the form (PD$'$). First, for all $i$ with $K_i = \mathbb{R}^{n_i}$, define $x_i^{new} = [x_i^+; x_i^-]$, $c_i^{new} = [c_i; -c_i]$, $A_i^{new} = [A_i, -A_i]$, $K_i^{new} = \mathbb{R}_+^{n_i^{new}}$, $n_i^{new} = 2n_i$ and replace $c_i$, $A_i$, $K_i$, $n_i$ by $c_i^{new}$, $A_i^{new}$, $K_i^{new}$ and $n_i^{new}$ respectively. After the above adjustment and necessary rearrangement (grouping together the same types of $K_i$), one has $\mathcal{K} = \mathbb{R}_+^{n_l} \times \mathcal{Q}_{n_{q_1}} \times \cdots \times \mathcal{Q}_{n_{q_s}} \times \left(\mathcal{K}_{\exp}\right)^{k_e}$, $n_q = n_{q_1} + ... + n_{q_s}$, $n_e = 3k_e$. \\

Next we set the iterate $(x^0,y^0, z^0, \tau^0, \kappa^0, \theta^0)$ such that $x^0 \in \interior\left(\mathcal{K}\right)$, $z^0 \in \interior\left(\mathcal{K}^*\right)$, $y^0 \in \mathbb{R}^m$, $\tau^0 > 0$, $\kappa^0 > 0$, $\theta^0>0$. One strategy is to set $y^0 = 0$, $\tau^0 = \kappa^0 = \theta^0 = 1$. For $x^0$ and $z^0$, we will take the analytical centers of the respective barrier function of $\mathcal{K}$ (and equivalently that of $\mathcal{K}^*$). In other words, we first find a LHSCB for the product cone $\mathcal{K}$ as the sum of its parts using the following simple fact.

Since we have found analytic expressions for the LHSCB for the nonnegative orthant, the Lorentz cone, the exponential cone and its dual cone, we have found a LHSCB $f$ for the product cone $\mathcal{K}$. For the initial iterate, take $y = 0$, $\tau^0 = \kappa^0 = \theta^0 = 1$, $x \in \relint \left(\mathcal{K}\right)$, $z\in\relint\left(\mathcal{K}^*\right)$. Specifically, let $\mathcal{K} = \mathcal{K}_1 \times \cdots \times \mathcal{K}_N$ where each $\mathcal{K}_j$ is either a nonnegative orthant, a Lorentz cone or an exponential cone. For each $j$, if $\mathcal{K}_j = \mathbb{R}_+^{n_j}$, set the corresponding sub-vectors $\left(x^0\right)_j = \left(z^0\right)_j = (1,\cdots, 1)^T \in \mathbb{R}_+^{n_j}$; if $\mathcal{K}_j = \mathcal{Q}^{n_j}$, set $\left(x^0\right)_j = \left(z^0\right)_j = (1,0,\cdots, 0)^T \in \mathcal{Q}^{n_j}$; if $\mathcal{K} = \mathcal{K}_{\exp}$, set $\left(x^0\right)_j = \left(z^0\right)_j = \iota^0$, where $\iota^0 =   (-1.0151, 1.2590, 0.5560)^T$ is the approximate solution to 
\[\iota + \tilde g^*(\iota) = 0.\]

In addition, compute the auxillary parameters $\bar{b}$, $\bar{c}$, $\bar{g}$, $\bar{\alpha}$ and set the initial central-path parameter $\mu^0 = \theta^0$.

\subsection{A typical iteration}\label{A_typical_iteration}
Henceforth the current and next iterates are denoted as  $ \bar x = (x,y, \tau, z,\kappa, \theta)$ and  $ \bar x^+ = (x^+, y^+, \tau^+, z^+,\kappa^+, \theta^+)$ respectively. \\

Given the current iterate $\bar x$, compute $\mu = \dfrac{x^T z + \tau \kappa}{\nu}$, where $\nu = \sum_{j=1}^N \nu_j$ is the parameter for the LHSCB for $\mathcal{K}$. Note that with the above initialization, it always holds that $\mu = \theta$. \\

Solve for the predictor search direction $\Delta \bar x^p$ from \eqref{predictor_system_mu} and approximately find

\[\alpha^p = \sup \left\{ \alpha > 0 \mid \bar x + \alpha \Delta \bar x^p \in \relint \left(\bar K\right)
 \right\}. \]
Note that we are not maintaining a central path neighborhood in addition to the underlying conic constraints. \\

Set $\sigma = \max\left\{(1-\alpha^p)^3, 0\right\}$ and solve for the combined search direction $\Delta \bar x$ from \eqref{combined_system_mu}. \\

\[\alpha^c = \left\{ \alpha > 0 \mid \bar x + \alpha \Delta \bar x^p \in \relint \left(\bar K\right)
\right\}. \]

Set $\alpha' = 0.98 \alpha^c$ and update the iterate
\[\bar x^+ = \bar x + \alpha' \Delta\bar x.\]

For approximately finding $\alpha^p$ (and similarly $\alpha^c$), we adopt a bisection strategy and find $\alpha^p = \beta \cdot \sup \left\{ \alpha > 0 \mid \bar x + \alpha \Delta \bar x^p \in \relint \left(\bar K\right)
\right\}$ for some $\beta \in (0.95,1]$. To solve the linear systems \eqref{predictor_system_mu} and \eqref{combined_system_mu}, we adopt the strategy in \cite{SDPT3_2010} of first solving a Schur complement equation.
\subsection{Termination conditions}
We are interested in either a solution or a certificate of infeasibility of (PD). Similar to Section 5.4 in \cite{Skarjaa_and_Ye}, there are 3 possibilities. 
\begin{enumerate}
	\item We declare optimality (primal and dual feasibility with an approximate optimal solution found) if
	\begin{align}
		\left\| Ax-\tau b \right\|_{\infty} &\leq \epsilon \cdot \max \left\{1, \left\|[A,b]\right\|_{\infty}\right\} \label{P_termination}\\
		\left\|A^T y + z-c\tau\right\|_{\infty} &\leq \epsilon \cdot \max \left\{1, \left\|A^T, I , -c\right\|_{\infty}\right\}\label{D_termination}\\
		\left|c^T x/\tau - b^T y/\tau\right|  &\leq \epsilon\cdot\left(1+\left|b^T y/\tau\right|\right).\label{A_termination}
	\end{align}
	In this case, the approximate optimal solution $(x,y,z)/\tau$ is returned.
	\item We declare primal and/or dual infeasibility if \eqref{P_termination}, \eqref{D_termination} and 
	\begin{align}
		\left|-c^T x+b^T y - \kappa \right| &\leq \epsilon\cdot \max \left\{1, \left\|\left[-c^T, b^T, 1\right]\right\|_{\infty}\right\} \label{G_termination}\\
		\tau &\leq \epsilon \cdot 10^{-2} \cdot \left\{1,\kappa\right\}\label{T_terminal}
	\end{align}
	hold. If $b^T y>0$ ($c^T x<0$, respectively), the problem is primal infeasible (dual infeasible, respectively).
	\item We declare that the problem is ill-posed if 
	\begin{align*}
		\kappa &\leq \epsilon \cdot 10^{-2}\cdot \min \left\{1,\tau\right\}\\
		\mu &\leq \epsilon \cdot 10^{-2}\cdot \mu^0.
	\end{align*}
\end{enumerate}

\newpage
\newpage
\bibliography{references}{}
\bibliographystyle{plain}
\end{document}